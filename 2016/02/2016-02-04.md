### [Grokking V8 closures for fun (and profit?)](http://mrale.ph/blog/2012/09/23/grokking-v8-closures-for-fun.html)

#### Context allocation

* V8 creates a `Context` when we **enter the outer function**, not when we create a closure itself. So watch out for hot loops referencing those variables in the outer function. The optimizing compiler cannot allocate these variables to registers i.e. all operations must go through the memory, which is much slower.
  * It looks like this:

    ```javascript
    function outer() {
      var thisWillBeInMem = 0;
      for(var i = 0; i < 1000000; ++i) {
        // do something with `thisWillBeInMem`
      }

      return function() {
        // references `thisWillBeInMem` and
        // creates the closure, then the
        // variable can't be put into the registers
      }
    }
    ```
  * Possible improvement: [register promotion](http://reference.kfupm.edu.sa/content/r/e/register_promotion_in_c_programs__251236.pdf)
* `Context` will be created **eagerly** and will be shared by closures created in the same scope. Nested closures lead to nested pointers
  * This eager scheme could lead to memory leaks:

  ```javascript
  function outer() {
    var x = HUGE;  // huge object
    function inner() {
      var y = GIANT;  // giant object :-)

      use(x);  // usage of x cause it to be allocated to the context

      // note: innerF is never actually called
      function innerF() {
        use(y);  // usage of y causes it to be allocated to the context
      }

      function innerG() {
        /* use nothing */
      }

      return innerG;
    }

    return inner();
  }

  var o = outer();  // o will retain HUGE and GIANT
  // even though they are not needed anymore after `outer()` is finished
  ```
* Contexts retain closures that created them
  * For async code with deeply nested callbacks, this could mean that the outermost callback will be kept alive until the innermost dies - so **the compiled code themselves could take up a lot of space**. The worst case: long-living outermost callbacks get **promoted to the old generation**, boom!
  * So, avoid nested callbacks in hot loops!
* **Heuristic for context allocation**
  * `eval` and `with` cause **all variables in all encosing scopes** to be context allocated
  * References to `arguments` in a non-strict function causes the parameters to be context-allocated
* **Functions that have to allocate a context are not inlined**
* Hot functions using `arguments` should
  * Either have `()` for formal parameters
  * Or be strict

#### Generated code

* Objects accessing properties through closures will be slower because they have to be loaded from the context, so there's **overhead for loading the context**
* Crankshaft can't use the info from the parser, so it can't even skip the checks for closure intentity when the results is very obvious from the parser's point of view
* The optimizing compiler can't even reuse the loaded context, it just load the context for each method call. So instead of load them from offsets, it will load the context first then load them from offsets to the context.
* So, in the closure object, for every getter call, there will be one more `mov -> cmp -> jnz`(for checking the getter's closure identity) and one more `mov` for loading context. Meanwhile the class object will only have one more `mov -> cmp -> jnz` for checking prototype maps, and some other guards without `mov`.
* It becomes even worse when you create multiple instances of closure objects: type feedback from different instances gets mixed up together turning getter call sites into **megamorphic calls**, so **the getters are not inlined anymore**(have to be called via `generic CallFunctionStub` and check closure identities)! Meanwhile the code generated for classic objects is still the same.
  * Possible improvement: [Checking `SharedFunctionInfo` identity instead of closure identity for inlining](https://bugs.chromium.org/p/v8/issues/detail?id=2206)

#### Notes

* Compared to Lua's flat closure, V8 implement the closure in a nested manner. This could be bad(indirect references overhead and all), but can also be good(some GC likes it small, better locality, smaller creation cost, .etc)
* V8 dedicates register `esi` to hold the pointer to the current context so that it doesn't have to be loaded from the frame/closure
* The compiler can resolve variables into fixed indices during compilation, reducing late-binding/lookup overhead and even needs for inline caches
* Actual operations and type guards are separated. The compiler can do subexpression elimination (CSE) and **eliminate redundant guards** for similar variables
* Crankshaft inlines small methods(like simple getters) and eliminates calls for them(no more stack pushing & popping, .etc). To do this, it also **keeps a guard against the hidden class of the prototypes** to make sure the methods are not modified, thus safe to be inlined.
* V8 **shares unoptimized code** across all closures produced from the same function literal, and attaches inline caches and utilities collecting type feedback to them. Therefore **type feedback is shared and mixed**(before it doesn't even share this code...ouch).
* If you call the closure object constructor twice, the callsites for the getters will become **megamorphic** because the identity of there call targets does not match anymore

